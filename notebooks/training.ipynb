{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ°Ô∏è Phishing Email Detection - DistilBERT Fine-tuning\n",
                "\n",
                "**Project:** Hybrid AI Defense - Closing the Detection Gap Against AI-Generated Phishing  \n",
                "**Author:** Ramkumar  \n",
                "**Model:** DistilBERT (HuggingFace Transformers)  \n",
                "**Framework:** PyTorch\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required libraries\n",
                "!pip install transformers datasets torch scikit-learn pandas numpy accelerate -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Upload Data\n",
                "\n",
                "Upload your processed CSV files from `data/processed/`:\n",
                "- `train.csv`\n",
                "- `validation.csv`\n",
                "- `test.csv`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upload files (for Google Colab)\n",
                "from google.colab import files\n",
                "uploaded = files.upload()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Load data\n",
                "train_df = pd.read_csv('train.csv')\n",
                "val_df = pd.read_csv('validation.csv')\n",
                "test_df = pd.read_csv('test.csv')\n",
                "\n",
                "print(f\"Train: {len(train_df)} samples\")\n",
                "print(f\"Validation: {len(val_df)} samples\")\n",
                "print(f\"Test: {len(test_df)} samples\")\n",
                "print(f\"\\nLabel distribution (train):\")\n",
                "print(train_df['label'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prepare Dataset for Transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import Dataset, DatasetDict\n",
                "from transformers import AutoTokenizer\n",
                "\n",
                "# Load DistilBERT tokenizer\n",
                "MODEL_NAME = \"distilbert-base-uncased\"\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
                "\n",
                "# Convert pandas to HuggingFace Dataset\n",
                "train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
                "val_dataset = Dataset.from_pandas(val_df[['text', 'label']])\n",
                "test_dataset = Dataset.from_pandas(test_df[['text', 'label']])\n",
                "\n",
                "dataset = DatasetDict({\n",
                "    'train': train_dataset,\n",
                "    'validation': val_dataset,\n",
                "    'test': test_dataset\n",
                "})\n",
                "\n",
                "print(dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tokenization function\n",
                "def tokenize_function(examples):\n",
                "    return tokenizer(\n",
                "        examples['text'],\n",
                "        padding='max_length',\n",
                "        truncation=True,\n",
                "        max_length=512  # DistilBERT max length\n",
                "    )\n",
                "\n",
                "# Tokenize all datasets\n",
                "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
                "\n",
                "# Remove text column (not needed for training)\n",
                "tokenized_dataset = tokenized_dataset.remove_columns(['text'])\n",
                "\n",
                "# Rename label to labels (required by Trainer)\n",
                "tokenized_dataset = tokenized_dataset.rename_column('label', 'labels')\n",
                "\n",
                "# Set format for PyTorch\n",
                "tokenized_dataset.set_format('torch')\n",
                "\n",
                "print(\"Tokenization complete!\")\n",
                "print(tokenized_dataset)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load DistilBERT Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoModelForSequenceClassification\n",
                "\n",
                "# Load pre-trained DistilBERT for binary classification\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    MODEL_NAME,\n",
                "    num_labels=2,  # Binary: 0=Legit, 1=Phishing\n",
                "    id2label={0: \"LEGITIMATE\", 1: \"PHISHING\"},\n",
                "    label2id={\"LEGITIMATE\": 0, \"PHISHING\": 1}\n",
                ")\n",
                "\n",
                "print(f\"Model loaded: {MODEL_NAME}\")\n",
                "print(f\"Parameters: {model.num_parameters():,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import TrainingArguments, Trainer\n",
                "\n",
                "# Define metrics function\n",
                "def compute_metrics(eval_pred):\n",
                "    logits, labels = eval_pred\n",
                "    predictions = np.argmax(logits, axis=-1)\n",
                "    \n",
                "    accuracy = accuracy_score(labels, predictions)\n",
                "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
                "        labels, predictions, average='binary'\n",
                "    )\n",
                "    \n",
                "    return {\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'f1': f1\n",
                "    }\n",
                "\n",
                "# Training arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir='./results',\n",
                "    eval_strategy='epoch',\n",
                "    save_strategy='epoch',\n",
                "    learning_rate=2e-5,\n",
                "    per_device_train_batch_size=16,\n",
                "    per_device_eval_batch_size=16,\n",
                "    num_train_epochs=3,\n",
                "    weight_decay=0.01,\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model='f1',\n",
                "    logging_dir='./logs',\n",
                "    logging_steps=50,\n",
                "    report_to='none',  # Disable wandb\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "print(\"Training configuration set!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Trainer\n",
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_dataset['train'],\n",
                "    eval_dataset=tokenized_dataset['validation'],\n",
                "    compute_metrics=compute_metrics\n",
                ")\n",
                "\n",
                "print(\"Trainer initialized!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Train the Model üöÄ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start training\n",
                "print(\"Starting training...\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "trainer.train()\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate on test set\n",
                "print(\"Evaluating on test set...\")\n",
                "results = trainer.evaluate(tokenized_dataset['test'])\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"TEST RESULTS\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Accuracy:  {results['eval_accuracy']:.4f}\")\n",
                "print(f\"Precision: {results['eval_precision']:.4f}\")\n",
                "print(f\"Recall:    {results['eval_recall']:.4f}\")\n",
                "print(f\"F1 Score:  {results['eval_f1']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detailed predictions and confusion matrix\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Get predictions\n",
                "predictions = trainer.predict(tokenized_dataset['test'])\n",
                "preds = np.argmax(predictions.predictions, axis=-1)\n",
                "labels = predictions.label_ids\n",
                "\n",
                "# Confusion Matrix\n",
                "cm = confusion_matrix(labels, preds)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "            xticklabels=['Legitimate', 'Phishing'],\n",
                "            yticklabels=['Legitimate', 'Phishing'])\n",
                "plt.title('Confusion Matrix - Test Set')\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nTrue Negatives (Legit‚ÜíLegit): {cm[0][0]}\")\n",
                "print(f\"False Positives (Legit‚ÜíPhishing): {cm[0][1]}\")\n",
                "print(f\"False Negatives (Phishing‚ÜíLegit): {cm[1][0]}\")\n",
                "print(f\"True Positives (Phishing‚ÜíPhishing): {cm[1][1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Analyze Human vs LLM Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze by source (human vs LLM)\n",
                "test_df_with_preds = test_df.copy()\n",
                "test_df_with_preds['predicted'] = preds\n",
                "test_df_with_preds['correct'] = test_df_with_preds['label'] == test_df_with_preds['predicted']\n",
                "\n",
                "print(\"=\"*50)\n",
                "print(\"ACCURACY BY SOURCE\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for source in ['human', 'llm']:\n",
                "    source_df = test_df_with_preds[test_df_with_preds['source'] == source]\n",
                "    accuracy = source_df['correct'].mean()\n",
                "    print(f\"{source.upper()}-generated emails: {accuracy:.4f} ({len(source_df)} samples)\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"ACCURACY BY SOURCE x TYPE\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for source in ['human', 'llm']:\n",
                "    for label in [0, 1]:\n",
                "        subset = test_df_with_preds[(test_df_with_preds['source'] == source) & \n",
                "                                     (test_df_with_preds['label'] == label)]\n",
                "        if len(subset) > 0:\n",
                "            accuracy = subset['correct'].mean()\n",
                "            label_name = 'Legit' if label == 0 else 'Phishing'\n",
                "            print(f\"{source.upper()} {label_name}: {accuracy:.4f} ({len(subset)} samples)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Save the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model and tokenizer\n",
                "MODEL_SAVE_PATH = './phishing_detector_model'\n",
                "\n",
                "trainer.save_model(MODEL_SAVE_PATH)\n",
                "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
                "\n",
                "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download model (for Colab)\n",
                "!zip -r phishing_detector_model.zip phishing_detector_model/\n",
                "files.download('phishing_detector_model.zip')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Test with Sample Email"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick test function\n",
                "def predict_email(text):\n",
                "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
                "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "        probs = torch.softmax(outputs.logits, dim=-1)\n",
                "        prediction = torch.argmax(probs, dim=-1).item()\n",
                "    \n",
                "    label = 'PHISHING ‚ö†Ô∏è' if prediction == 1 else 'LEGITIMATE ‚úÖ'\n",
                "    confidence = probs[0][prediction].item() * 100\n",
                "    \n",
                "    print(f\"Prediction: {label}\")\n",
                "    print(f\"Confidence: {confidence:.2f}%\")\n",
                "    return prediction, confidence\n",
                "\n",
                "# Test examples\n",
                "print(\"=\"*50)\n",
                "print(\"TEST 1: Phishing-like email\")\n",
                "print(\"=\"*50)\n",
                "predict_email(\"URGENT: Your account has been compromised! Click here immediately to verify your identity or your account will be suspended. [URL]\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"TEST 2: Legitimate-like email\")\n",
                "print(\"=\"*50)\n",
                "predict_email(\"Hi team, just a reminder that our weekly meeting is scheduled for tomorrow at 3 PM. Please review the attached agenda beforehand.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ‚úÖ Training Complete!\n",
                "\n",
                "**Next Steps:**\n",
                "1. Download the saved model (`phishing_detector_model.zip`)\n",
                "2. Extract to `model/saved_models/` in your project\n",
                "3. Proceed to Week 2: Backend & URL Analysis"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}